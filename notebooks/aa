# --- STEP 1: Get your files from GitHub ---
import os

# Clone your specific repository
!git clone https://github.com/doodaa25/FifthProject

# Move into the notebooks folder
repo_name = "FifthProject" 
if os.path.exists(repo_name):
    os.chdir(os.path.join(repo_name, 'notebooks'))
    print(f"✅ Changed directory to: {os.getcwd()}")
else:
    print("❌ Repository not found. Please check the git clone URL.")

# --- STEP 2: Import Libraries & Download Data ---
import nltk
import matplotlib.pyplot as plt # Library for the charts
from nltk.tokenize import word_tokenize
from nltk.tag import pos_tag

# Download necessary NLTK data
nltk.download('punkt', quiet=True)
nltk.download('averaged_perceptron_tagger', quiet=True)
nltk.download('averaged_perceptron_tagger_eng', quiet=True) # Added for compatibility
nltk.download('punkt_tab', quiet=True)

# --- STEP 3: Define Calculation Function ---
def calculate_lexical_density(text):
    # Filter for alphabetic words only
    tokens = [word.lower() for word in word_tokenize(text) if word.isalpha()]
    total_words = len(tokens)
    
    if total_words == 0: return 0
    
    tagged_tokens = pos_tag(tokens)
    # Tags: N=Noun, V=Verb, J=Adjective, R=Adverb
    content_word_tags = ('N', 'V', 'J', 'R')
    content_words = [word for word, tag in tagged_tokens if tag.startswith(content_word_tags)]
    
    return (len(content_words) / total_words) * 100

# --- STEP 4: Analyze and Plot ---
data_folder = "../data"
files_to_analyze = [
    "The Project Gutenberg eBook of Anna Karenina, by Leo Tolstoy.txt",
    "The Project Gutenberg eBook of War and Peace, by Leo Tolstoy.txt"
]

results = {} # Dictionary to store data for the graph

print(f"\n{'Book Name':<60} | {'Density':<10}")
print("-" * 80)

for filename in files_to_analyze:
    file_path = os.path.join(data_folder, filename)
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()
            
            # Calculate density
            density = calculate_lexical_density(text)
            
            # Clean up the name for the chart
            clean_name = filename.replace("The Project Gutenberg eBook of ", "").replace(".txt", "")
            
            # Store result for plotting
            results[clean_name] = density
            
            print(f"{clean_name:<60} | {density:.2f}%")
            
    except FileNotFoundError:
        print(f"Error: Could not find {filename}. Check if the file exists in the 'data' folder.")

# --- STEP 5: Generate the Image ---
if results:
    names = list(results.keys())
    values = list(results.values())

    plt.figure(figsize=(10, 6))
    
    # Create the bars
    bars = plt.bar(names, values, color=['#4CAF50', '#2196F3']) # Green and Blue bars
    
    plt.ylabel('Lexical Density (%)')
    plt.title('Lexical Density Comparison: Tolstoy\'s Works')
    plt.ylim(0, 60) # Set limit to make it look cleaner

    # Add text numbers on top of bars
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2.0, height, f'{height:.2f}%', ha='center', va='bottom')

    print("\nGenerating Chart...")
    plt.show()
