{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Density & Sentence Length Analysis\n",
    "\n",
    "This notebook performs a comparative analysis of Leo Tolstoy's *Anna Karenina* and *War and Peace*.\n",
    "\n",
    "## Metrics Calculated:\n",
    "1.  **Lexical Density:** The percentage of content words (Nouns, Verbs, Adjectives, Adverbs) vs. total tokens.\n",
    "2.  **Sentence Length Distribution:** Statistical analysis of how long the sentences are in each book.\n",
    "\n",
    "**Formula:** $Lexical Density = \\frac{Total Content Words}{Total Words} \\times 100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# --- Setup & Download NLTK Data ---\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "    nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
    "    nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "print(\"Libraries loaded and NLTK data ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(text):\n",
    "    \"\"\"\n",
    "    Calculates two metrics:\n",
    "    1. Lexical Density (percentage)\n",
    "    2. List of sentence lengths (for box plot)\n",
    "    \"\"\"\n",
    "    # --- 1. Lexical Density ---\n",
    "    # Filter for alphabetic words only\n",
    "    tokens = [word.lower() for word in word_tokenize(text) if word.isalpha()]\n",
    "    total_words = len(tokens)\n",
    "    \n",
    "    if total_words == 0: return 0, []\n",
    "    \n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    # Tags: N=Noun, V=Verb, J=Adjective, R=Adverb\n",
    "    content_word_tags = ('N', 'V', 'J', 'R')\n",
    "    content_words = [word for word, tag in tagged_tokens if tag.startswith(content_word_tags)]\n",
    "    \n",
    "    density = (len(content_words) / total_words) * 100\n",
    "    \n",
    "    # --- 2. Sentence Lengths ---\n",
    "    sentences = sent_tokenize(text)\n",
    "    # Count words in each sentence (filtering out punctuation)\n",
    "    sentence_lengths = [len([w for w in word_tokenize(s) if w.isalpha()]) for s in sentences]\n",
    "    \n",
    "    return density, sentence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Analysis Logic ---\n",
    "data_folder = \"../data\"\n",
    "files_to_analyze = [\n",
    "    \"The Project Gutenberg eBook of Anna Karenina, by Leo Tolstoy.txt\",\n",
    "    \"The Project Gutenberg eBook of War and Peace, by Leo Tolstoy.txt\"\n",
    "]\n",
    "\n",
    "results = {} \n",
    "\n",
    "print(f\"{'Book Name':<60} | {'Density':<10} | {'Avg Sen Len'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for filename in files_to_analyze:\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "    \n",
    "    # Check if file exists (handle both relative path and current dir)\n",
    "    if not os.path.exists(file_path):\n",
    "        file_path = filename \n",
    "        \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            density, sen_lengths = calculate_metrics(text)\n",
    "            \n",
    "            # Clean up the name for the chart\n",
    "            clean_name = filename.replace(\"The Project Gutenberg eBook of \", \"\").replace(\".txt\", \"\")\n",
    "            \n",
    "            # Store result for plotting\n",
    "            results[clean_name] = {'density': density, 'lengths': sen_lengths}\n",
    "            \n",
    "            # Calculate avg length for print output\n",
    "            avg_len = sum(sen_lengths) / len(sen_lengths) if sen_lengths else 0\n",
    "            print(f\"{clean_name:<60} | {density:.2f}%     | {avg_len:.1f} words\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ Error: Could not find '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization ---\n",
    "if results:\n",
    "    names = list(results.keys())\n",
    "    \n",
    "    # Create a layout with 2 Graphs (1 Row, 2 Columns)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Graph 1: Lexical Density (Bar Chart)\n",
    "    densities = [results[n]['density'] for n in names]\n",
    "    bars = ax1.bar(names, densities, color=['#4CAF50', '#2196F3'])\n",
    "    ax1.set_title('Lexical Density Comparison')\n",
    "    ax1.set_ylabel('Density (%)')\n",
    "    ax1.set_ylim(0, 60)\n",
    "    \n",
    "    # Add numbers on bars\n",
    "    for bar in bars:\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "                 f'{bar.get_height():.2f}%', ha='center', va='bottom')\n",
    "\n",
    "    # Graph 2: Sentence Length Distribution (Box Plot)\n",
    "    lengths_data = [results[n]['lengths'] for n in names]\n",
    "    \n",
    "    # Filter outliers > 80 words for cleaner visualization\n",
    "    filtered_data = [[l for l in d if l < 80] for d in lengths_data]\n",
    "    \n",
    "    ax2.boxplot(filtered_data, labels=names, patch_artist=True, \n",
    "                boxprops=dict(facecolor='#FFC107'))\n",
    "    ax2.set_title('Sentence Length Distribution (Box Plot)')\n",
    "    ax2.set_ylabel('Words per Sentence')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}